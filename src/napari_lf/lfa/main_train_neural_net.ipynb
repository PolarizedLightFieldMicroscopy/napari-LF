{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network training for Napari-LF\n",
    "\n",
    "Napari-LF neural net integration relies on Pytorch-lightning workflow. Which provides general functions for loading data, training, inference, etc. That can be used with any neural network.\n",
    "This script is intended for preparing a network to use with Napari-LF.\n",
    "\n",
    "## Instructions\n",
    "1. Import required libraries and desired network to train.\n",
    "2. Gather needed information from user\n",
    "3. Create a network.\n",
    "4. Load data for training.\n",
    "5. Train network.\n",
    "6. Store network in napari-LF compatible format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required libraries and desired network to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "# Let's train a VCDNet. This defines which network we will train\n",
    "from neural_nets.VCDNet import  VCDNet as NN\n",
    "# Or:\n",
    "# from neural_nets.LFMNet import  LFMNet as NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gather needed information from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 1\n",
    "# What is the shape of our Light-field [angular-u, angular-v, spatial-s, spatial-t]\n",
    "LFshape = [33,33,39,39]     # For the case of the MouseBrain dataset\n",
    "LF_2D_shape = [LFshape[0]*LFshape[2], LFshape[1]*LFshape[3]]\n",
    "# How many depths are present in each volume?\n",
    "n_depths = 64\n",
    "\n",
    "# Define training parameters\n",
    "training_settings = {}\n",
    "# Learning rate\n",
    "training_settings['lr'] = 1e-3    \n",
    "# Batch size              \n",
    "training_settings['batch_size'] = 2  \n",
    "# max epochs to train        \n",
    "training_settings['epochs'] = 500\n",
    "# Which image-volume pairs to use\n",
    "training_settings['images_ids'] = list(range(100))                                               \n",
    "# Where is the data\n",
    "training_settings['dataset_path'] = 'D:/BrainImagesJosuePage/Brain_40x_64Depths_362imgs.h5'    \n",
    "# Where to store the trained network?\n",
    "training_settings['output_dir'] = 'C:/Users/OldenbourgLab2/Code/napari-LF-neural_nets/examples/pretrained_networks/'    # If left blank the logs and trained network are stored at ./lightning_logs/version_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN(LF_2D_shape, (n_depths,)+tuple(LF_2D_shape), \n",
    "         network_settings_dict={'LFshape' : LFshape}, \n",
    "         training_settings_dict=training_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading img:   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 "
     ]
    }
   ],
   "source": [
    "net.configure_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m tb_logger \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Do we log to the default directory? or to a specified one\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(training_settings[\u001b[39m'\u001b[39m\u001b[39moutput_dir\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# Do we have a path for the logging?\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[39m# Define network type\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     network_prefix \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m loggers \u001b[39mas\u001b[39;00m pl_loggers\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_settings' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a trainer\n",
    "tb_logger = True\n",
    "# Do we log to the default directory? or to a specified one\n",
    "if len(training_settings['output_dir']) > 0: # Do we have a path for the logging?\n",
    "    # Define network type\n",
    "    network_prefix = net.__class__.__name__\n",
    "    from pytorch_lightning import loggers as pl_loggers\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir=f\"{training_settings['output_dir']}/\", name=network_prefix)\n",
    "    output_path = f\"{training_settings['output_dir']}/{network_prefix}\"\n",
    "    trainer = pl.Trainer(logger=tb_logger, gpus=n_gpus, precision=32, max_epochs=net.get_train_setting('epochs'))\n",
    "else:\n",
    "    trainer = pl.Trainer(logger=tb_logger, gpus=n_gpus, precision=32, max_epochs=net.get_train_setting('epochs'))\n",
    "    output_path = './lightning_logs/'\n",
    "    \n",
    "\n",
    "print(f'###################### Logging to: {output_path}')\n",
    "print(f'run tensorboard --logdir={output_path} in the console')\n",
    "trainer.fit(model=net, train_dataloaders=net.train_loader, val_dataloaders=net.val_loader)\n",
    "print(f'###################### Logging to: {output_path}')\n",
    "print(f'run tensorboard --logdir={output_path} in the console')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('napari-new': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adefa1ab0f692421d76c5f439f08fdb2194ecaa0be285eca5571b46bfcc0e371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
